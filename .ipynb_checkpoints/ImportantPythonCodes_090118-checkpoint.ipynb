{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Index of an item in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(df1).index('NoOfBirthDatesSearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a pandas column data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2[['Warning1']] = df2[['Warning1']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a value in  a cell in pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.set_value(row_number, Column name, 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace a certain string with another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.replace(\"[\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NA with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a column whicg got items like 101,102,103.. to put them in different columns and do one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "def one_hot_encode_tags_Income_Sources(df):\n",
    "    df.Income_Sources=df.Income_Sources.str.replace(\",\",\" \")\n",
    "    vect = CountVectorizer()\n",
    "    X = vect.fit_transform(df.Income_Sources)\n",
    "    df=df.join(pd.DataFrame(X.toarray(), columns=vect.get_feature_names()))\n",
    "    df.drop(\"Income_Sources\",axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore warnings. Warning wont be shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = probxgbrf\n",
    "preds = probs \n",
    "fpr, tpr, threshold = metrics.roc_curve(test_y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "fpr2, tpr2, threshold = metrics.roc_curve(test_y, prob_sc2)\n",
    "fpr3, tpr3, threshold = metrics.roc_curve(test_y, df_porb['probxgfinaprobxgbrf'])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Final logistic model = %0.2f' % roc_auc_score(test_y, probxgbrf))\n",
    "plt.plot(fpr2,tpr2,label=\"Scorecard 2.0, auc=\"+str(roc_auc_score(test_y, prob_sc2)))\n",
    "plt.plot(fpr3,tpr3,label=\"Final XGBoost model, auc=\"+str(roc_auc_score(test_y, df_porb['probxgfinaprobxgbrf'])))\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform grid search  cross validation with the specified test set. tune parameters to optimize the performance of a specified test data set. To do a general cross validation change the value of CV parameter(Ex: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_test_fold = []\n",
    "\n",
    "# put -1 here, so they will be in training set\n",
    "for i in range(len(train_x)):\n",
    "    my_test_fold.append(-1)\n",
    "\n",
    "# for all greater indices, assign 0, so they will be put in test set\n",
    "for i in range(len(test_x)):\n",
    "    my_test_fold.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit\n",
    "param = {\n",
    "'n_estimators':[200,100,10],\n",
    "'max_depth':[5],\n",
    "'min_child_weight':[3],\n",
    "'reg_alpha':[6],\n",
    "'gamma':[0.6],\n",
    "'learning_rate':[0.09]\n",
    "}\n",
    "\n",
    "\n",
    "# https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( \n",
    "        objective= 'reg:linear', \n",
    "        seed=1), \n",
    "    param_grid = param, \n",
    "    scoring='roc_auc',\n",
    "    cv = list(PredefinedSplit(test_fold=my_test_fold).split(new_data_df, df_y)),\n",
    "    verbose = 1)\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "# mean_squared_error alternative.\n",
    "\n",
    "gsearch1.fit(new_data_df, df_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive feature elimination method for feature selection. To do with other algorithms like xgboost, change the model at parameter 'estimator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr=LogisticRegression(C=0.8)\n",
    "\n",
    "rfe = RFE(estimator=lr, n_features_to_select=40, step=2)\n",
    "rfe.fit(new_data_df, df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining probabilities of multiple models. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probxgbrf=[(1*x + 1.6*y+0.6*z)/3.2\n",
    "           for x, y,z in zip(probxgb, probxgbf,problr)]\n",
    "roc_auc_score(test_y, probxgbrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a multi dimensional list and convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1=[[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(0,len(df)):\n",
    "    x=df.iloc[i][1]\n",
    "    AdvisorLoanID=df.iloc[i][0]\n",
    "\n",
    "    crs=creditSearchLast2Weeks(x)\n",
    "    crsFN=creditSearchLast2WeeksOF(x)\n",
    "    csrBK=creditSearchLast2WeeksBK(x)\n",
    "    No_CA=NocurrentAccountsTOTAL(x)\n",
    "    Age_oldca=AgeOldestCurrentAccounts(x)\n",
    "    No_BDAYS=NoOfBirthDatesACC(x)\n",
    "    No_BDAYS_seearch=NoOfBirthDatesSearch(x)\n",
    "    \n",
    "    \n",
    "    list1[0].append(AdvisorLoanID)\n",
    "    list1[1].append(crs)\n",
    "    list1[2].append(crsFN)\n",
    "    list1[3].append(csrBK)\n",
    "    list1[4].append(No_CA)\n",
    "    list1[5].append(Age_oldca)\n",
    "    list1[6].append(No_BDAYS)\n",
    "    list1[7].append(No_BDAYS_seearch)\n",
    "    list1[8].append(TimeAfterTheLatestDefault(x))\n",
    "    list1[9].append(Telecom(x))\n",
    "    list1[10].append(creditlineCount(x))\n",
    "    list1[11].append(AgeOldestAccounts(x))\n",
    "    list1[12].append(timesBalExceedLimitRecent12AllAcc(x))\n",
    "    list1[13].append(AvgAmountBalExceedLimitRecent12AllAcc(x))\n",
    "    list1[14].append(MostRecentStutusOfDefaultedLoans(x))\n",
    "    list1[15].append(AvgAmountArrearsCreditcardsLast3month(x))\n",
    "    list1[16].append(AvgAmountArrearsCurrentACLast3month(x))\n",
    "    list1[17].append(AvgBalanceCurrentACLast3month(x))\n",
    "    list1[18].append(creditSearchLast2WeeksFN(x))\n",
    "    \n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "df1['AdvisorLoanID']=list1[0]\n",
    "df1['creditSearchLast2Weeks']=list1[1]\n",
    "df1['creditSearchLast2WeeksOF']=list1[2]\n",
    "df1['creditSearchLast2WeeksBK']=list1[3]\n",
    "df1['NocurrentAccountsTOTAL']=list1[4]\n",
    "df1['AgeOldestCurrentAccounts']=list1[5]\n",
    "df1['NoOfBirthDatesACC']=list1[6]\n",
    "df1['NoOfBirthDatesSearch']=list1[7]\n",
    "df1['TimeAfterTheLatestDefault']=list1[8]\n",
    "df1['Telecom']=list1[9]\n",
    "df1['creditlineCount']=list1[10]\n",
    "df1['AgeOldestAccounts']=list1[11]\n",
    "df1['timesBalExceedLimitRecent12AllAcc']=list1[12]\n",
    "df1['AvgAmountBalExceedLimitRecent12AllAcc']=list1[13]\n",
    "df1['MostRecentStutusOfDefaultedLoans']=list1[14]\n",
    "df1['AvgAmountArrearsCreditcardsLast3month']=list1[15]\n",
    "df1['AvgAmountArrearsCurrentACLast3month']=list1[16]\n",
    "df1['AvgBalanceCurrentACLast3month']=list1[17]\n",
    "df1['creditSearchLast2WeeksFN']=list1[18]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Visualise a decision tree. First fit a tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "\n",
    "features=list(new_data_df)\n",
    "\n",
    "\n",
    "def get_code(tree, feature_names, target_names,\n",
    "             spacer_base=\"    \"):\n",
    "    \"\"\"Produce psuedo-code for decision tree.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    tree -- scikit-leant DescisionTree.\n",
    "    feature_names -- list of feature names.\n",
    "    target_names -- list of target (class) names.\n",
    "    spacer_base -- used for spacing code (default: \"    \").\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    based on http://stackoverflow.com/a/30104792.\n",
    "    \"\"\"\n",
    "    left      = tree.tree_.children_left\n",
    "    right     = tree.tree_.children_right\n",
    "    threshold = tree.tree_.threshold\n",
    "    features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "    value = tree.tree_.value\n",
    "\n",
    "    def recurse(left, right, threshold, features, node, depth):\n",
    "        spacer = spacer_base * depth\n",
    "        if (threshold[node] != -2):\n",
    "            print(spacer + \"if ( \" + features[node] + \" <= \" + \\\n",
    "                  str(threshold[node]) + \" ) {\")\n",
    "            if left[node] != -1:\n",
    "                    recurse(left, right, threshold, features,\n",
    "                            left[node], depth+1)\n",
    "            print(spacer + \"}\\n\" + spacer +\"else {\")\n",
    "            if right[node] != -1:\n",
    "                    recurse(left, right, threshold, features,\n",
    "                            right[node], depth+1)\n",
    "            print(spacer + \"}\")\n",
    "        else:\n",
    "            target = value[node]\n",
    "            for i, v in zip(np.nonzero(target)[1],\n",
    "                            target[np.nonzero(target)]):\n",
    "                target_name = target_names[i]\n",
    "                target_count = int(v)\n",
    "                print(spacer + \"return \" + str(target_name) + \\\n",
    "                      \" ( \" + str(target_count) + \" examples )\")\n",
    "\n",
    "    recurse(left, right, threshold, features, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_code(dt, features, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus as pydot\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "dot_data = StringIO()\n",
    "\n",
    "tree.export_graphviz(dt, out_file=dot_data,feature_names=features,filled=True, proportion=True)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save multiple dataframes in one excel file in different sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('pandas_multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "df1.to_excel(writer, sheet_name='Sheet1')\n",
    "df2.to_excel(writer, sheet_name='Sheet2')\n",
    "df3.to_excel(writer, sheet_name='Sheet3')\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query SQL with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "\n",
    "query = \" select left(PeriodEndDateKey, 6) as PeriodEndDate,LoanAmountTaken,CapitalBalanceWrittenOff, left(LoanStartDateKey, 6) as LoanStartDate, LSSLoanID \\\n",
    "FROM dw..FactMonthlyArchiveSnapshot \\\n",
    "where left(LoanStartDateKey, 6) >= 201701 and left(LoanStartDateKey, 6) <= 201703 \"\n",
    "\n",
    "\n",
    "engine_str = \"mssql+pyodbc://@TCSVVW8PSQL005\\SQL005/risk?driver=SQL Server\"\n",
    "\n",
    "engine = sqlalchemy.create_engine(engine_str)\n",
    "df = pd.read_sql(query, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot multiple graphs in one plot and set figure size and display legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in all_origin_months:\n",
    "    \n",
    "    get_cumWO(i)['%WO'].plot('line',label=i)  #plot for all the years in a loop\n",
    "    \n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 12) #  change the plot size\n",
    "#fig.savefig('test2png.png', dpi=100)   \n",
    "\n",
    "plt.xlabel('Months_On_Books')\n",
    "plt.ylabel('%W0')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a string a global variable. This wat we can create variables dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "globals()['df_M'+str(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a column pandas based on location. Following code will select column index number 2. note that Indexing start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.ix[:, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a column with strings seperated by / ex: aaa/bbb/ccc if we want to put each string in to different columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(txt):\n",
    "    try :\n",
    "        return txt.split(\"/\")\n",
    "    except :\n",
    "        return (\"No Label\", \"No Label\", \"No Label\") \n",
    "\n",
    "train_test['general_category'],train_test['subcategory_1'],train_test['subcategory_2'] = \\\n",
    "zip(*train_test['category_name'].apply(lambda x: split(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'GC' and fill that column with specified values conditioned on another column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test['GC']=0\n",
    "train_test.loc[ (train_test.general_category=='Beauty'),'GC']=19.671536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the number of unique items in a column pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test['brand_name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using countvectorizer or tfidvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = CountVectorizer(min_df=NAME_MIN_DF)\n",
    "X_name = count.fit_transform(df[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all the values of a dataframe to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with matplotlib pylplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "(train['price']).plot.hist(bins=50, figsize=(20,10), edgecolor='white',range=[0,250])\n",
    "plt.xlabel('price+', fontsize=17)\n",
    "plt.ylabel('frequency', fontsize=17)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.title('Price Distribution - Training Set', fontsize=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a value between strings which is computed in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"There are %d items that do not have a label.\" % train['category_name'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing git changes push 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
